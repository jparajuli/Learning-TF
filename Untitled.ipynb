{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declarations\n",
    "from __future__ import print_function, absolute_import\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters\n",
    "vocab_size = 256\n",
    "target_vocab_size = 256\n",
    "PAD = [0]\n",
    "EOS = [1]\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "buckets = [(10,10)]\n",
    "\n",
    "buckets[-1][1]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['l', 'e', 'h', 'o', 0, 0, 0, 0, 0], ['l', 'e', 'h', 'o', 0, 0, 0, 0, 0], ['l', 'e', 'h', 'o', 0, 0, 0, 0, 0], ['l', 'e', 'h', 'o', 0, 0, 0, 0, 0], ['l', 'e', 'h', 'o', 0, 0, 0, 0, 0], ['l', 'e', 'h', 'o', 0, 0, 0, 0, 0], ['l', 'e', 'h', 'o', 0, 0, 0, 0, 0], ['l', 'e', 'h', 'o', 0, 0, 0, 0, 0], ['l', 'e', 'h', 'o', 0, 0, 0, 0, 0], ['l', 'e', 'h', 'o', 0, 0, 0, 0, 0]]\n",
      "[['d', 'o', 'r', 'l', 'w', 0, 0, 0, 0, 0], ['d', 'o', 'r', 'l', 'w', 0, 0, 0, 0, 0], ['d', 'o', 'r', 'l', 'w', 0, 0, 0, 0, 0], ['d', 'o', 'r', 'l', 'w', 0, 0, 0, 0, 0], ['d', 'o', 'r', 'l', 'w', 0, 0, 0, 0, 0], ['d', 'o', 'r', 'l', 'w', 0, 0, 0, 0, 0], ['d', 'o', 'r', 'l', 'w', 0, 0, 0, 0, 0], ['d', 'o', 'r', 'l', 'w', 0, 0, 0, 0, 0], ['d', 'o', 'r', 'l', 'w', 0, 0, 0, 0, 0], ['d', 'o', 'r', 'l', 'w', 0, 0, 0, 0, 0]]\n",
      "[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "data_input = 'hello'\n",
    "chars_input= list(set(data_input))\n",
    "input_data= [chars_input + PAD * 5] * batch_size\n",
    "print(input_data)\n",
    "\n",
    "data_target = 'world'\n",
    "chars_target = list(set(data_target))\n",
    "target_data = [chars_target + PAD * 5] * batch_size\n",
    "print(target_data)\n",
    "\n",
    "target_weights= [[1.0]*6 + [0.0]*4] *batch_size \n",
    "print(target_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class seq2seq_test(object):\n",
    "    def __init__(self,source_vocab_size, target_vocab_size, buckets, size, num_layers, batch_size):\n",
    "        self.source_vocab_size = source_vocab_size\n",
    "        self.target_vocab_size = target_vocab_size\n",
    "        self.buckets = buckets\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        cell = single_cell = tf.nn.rnn_cell.GRUCell(size)\n",
    "        if num_layers > 1:\n",
    "            cell = tf.nn.rnn_cell.MultiRNNCell([single_cell]*num_layers)\n",
    "\n",
    "        def seq2seq_f(encoder_inputs, decoder_inputs, do_decode):\n",
    "            return tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(encoder_inputs, decoder_inputs,cell,\n",
    "                                                                        source_vocab_size, target_vocab_size, size,\n",
    "                                                                        feed_previous=do_decode) \n",
    "        #feed for inputs\n",
    "        self.encoder_inputs = []\n",
    "        self.decoder_inputs = []\n",
    "        self.target_weights = []\n",
    "\n",
    "        for i in range(buckets[-1][0]):\n",
    "            self.encoder_inputs.append(tf.placeholder(tf.int64, shape=[None], name=\"encoder{0}\".format(i)))\n",
    "\n",
    "        for i in range(buckets[-1][1]+1):\n",
    "            self.decoder_inputs.append(tf.placeholder(tf.int64, shape=[None], name=\"decoder{0}\". format(i)))\n",
    "            self.target_weights.append(tf.placeholder(tf.float32, shape=[None], name=\"weight{0}\".format(i))) \n",
    "\n",
    "        targets = [self.decoder_inputs[i + 1] for i in range(len(self.decoder_inputs) - 1)]\n",
    "        self.outputs, self.losses = tf.contrib.legacy_seq2seq.model_with_buckets(self.encoder_inputs, self.decoder_inputs,\n",
    "                                                                                targets,self.target_weights, buckets,\n",
    "                                                                                lambda x, y: seq2seq_f(x, y, False))\n",
    "\n",
    "        params = tf.trainable_variables()\n",
    "        self.updates=[]\n",
    "\n",
    "        for b in range(len(buckets)):\n",
    "            self.updates.append(tf.train.AdamOptimizer(learning_rate).minimize(self.losses[b]))\n",
    "\n",
    "\n",
    "        self.saver = tf.train.Saver(tf.global_variables())\n",
    "    \n",
    "    def step(self, session, encoder_inputs, decoder_inputs, target_weights, test):\n",
    "        bucket_id=0\n",
    "        encoder_size, decoder_size = self.buckets[bucket_id]\n",
    "        \n",
    "        input_feed = {}\n",
    "        \n",
    "        for l in range(encoder_size):\n",
    "            input_feed[self.encoder_inputs[l].name] = encoder_inputs[l] \n",
    "            \n",
    "        for l in range(decoder_size):\n",
    "            input_feed[self.decoder_inputs[l].name] = decoder_inputs[l]\n",
    "            input_feed[self.target_weights[l].name] = target_weights[l]\n",
    "            \n",
    "        last_target = self.decoder_inputs[decoder_size].name\n",
    "        input_feed[last_target] = np.zeros([self.batch_size], dtype=np.int32)\n",
    "        \n",
    "        if not test:\n",
    "            output_feed = [self.updates[bucket_id], self.losses[bucket_id]]\n",
    "        else:\n",
    "            output_feed = [self.losses[bucket_id]]\n",
    "            for l in range(decoder_size):\n",
    "                output_feed.append(self.outputs[bucket_id][l])\n",
    "                \n",
    "        outputs = session.run(output_feed, input_feed)\n",
    "        \n",
    "        if not test:\n",
    "            return outputs[0], outputs[1]\n",
    "        else:\n",
    "            return outputs[0], outputs[1:]\n",
    "      \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=seq2seq_test(256,256,[(10,10)],10,2,10)\n",
    "#perplexity, outputs = seq2seq_test.step(session, input_data, target_data, target_weights, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode(bytes):\n",
    "    return \"\".join(map(chr, bytes)).replace('\\x00', '').replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perplexity, outputs = model.step(session, input_data, target_data, target_weights, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'l'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-bec1cff72563>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtest_step\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-5a4ae51906b6>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, session, encoder_inputs, decoder_inputs, target_weights, test)\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[0moutput_feed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbucket_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_feed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\parajj\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\parajj\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    966\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubfeed_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m             \u001b[0mnp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[1;32mC:\\Users\\parajj\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \"\"\"\n\u001b[1;32m--> 531\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'l'"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    perplexity, outputs = model.step(session, input_data, target_data, target_weights, test=True)\n",
    "    words = np.argmax(outputs, axis=2)\n",
    "    print(words)\n",
    "    #word = decode(words[0])\n",
    "   # print(\"step %d, perplexity %f, output: hello %s?\" % (step, perplexity, word))\n",
    "    #if word == \"world\":\n",
    "     #   print(\">>>>> success! hello \" + word + \"! <<<<<<<\")\n",
    "      #  exit()\n",
    "step=0\n",
    "test_step=1\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as session:\n",
    "    model= seq2seq_test(vocab_size, target_vocab_size, buckets, size=10, num_layers=1, batch_size=batch_size)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    while True:\n",
    "        model.step(session, input_data, target_data, target_weights, test=False) \n",
    "        if step % test_step == 0:\n",
    "            test()\n",
    "            step=step+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.InteractiveSession\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a6f5d5a1a3d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\x00'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'type' object is not iterable"
     ]
    }
   ],
   "source": [
    "#\"\".join(map(chr, bytes)).replace('\\x00', '').replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
